{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2048 Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize a new game\n",
    "def new_game(n):\n",
    "    matrix = np.zeros([n,n])\n",
    "    return matrix\n",
    "\n",
    "#add 2 or 4 in the matrix\n",
    "def add_two(mat):\n",
    "    empty_cells = []\n",
    "    for i in range(len(mat)):\n",
    "        for j in range(len(mat[0])):\n",
    "            if(mat[i][j]==0):\n",
    "                empty_cells.append((i,j))\n",
    "    if(len(empty_cells)==0):\n",
    "        return mat\n",
    "    \n",
    "    index_pair = empty_cells[random.randint(0,len(empty_cells)-1)]\n",
    "    \n",
    "    prob = random.random()\n",
    "    if(prob>=0.9):\n",
    "        mat[index_pair[0]][index_pair[1]]=4\n",
    "    else:\n",
    "        mat[index_pair[0]][index_pair[1]]=2\n",
    "    return mat\n",
    "\n",
    "#to check state of the game\n",
    "def game_state(mat):\n",
    "    #if 2048 in mat:\n",
    "    #    return 'win'\n",
    "    \n",
    "    for i in range(len(mat)-1): #intentionally reduced to check the row on the right and below\n",
    "        for j in range(len(mat[0])-1): #more elegant to use exceptions but most likely this will be their solution\n",
    "            if mat[i][j]==mat[i+1][j] or mat[i][j+1]==mat[i][j]:\n",
    "                return 'not over'\n",
    "            \n",
    "    for i in range(len(mat)): #check for any zero entries\n",
    "        for j in range(len(mat[0])):\n",
    "            if mat[i][j]==0:\n",
    "                return 'not over'\n",
    "            \n",
    "    for k in range(len(mat)-1): #to check the left/right entries on the last row\n",
    "        if mat[len(mat)-1][k]==mat[len(mat)-1][k+1]:\n",
    "            return 'not over'\n",
    "        \n",
    "    for j in range(len(mat)-1): #check up/down entries on last column\n",
    "        if mat[j][len(mat)-1]==mat[j+1][len(mat)-1]:\n",
    "            return 'not over'\n",
    "        \n",
    "    return 'lose'\n",
    "\n",
    "\n",
    "def reverse(mat):\n",
    "    # reverse member of rows in mat\n",
    "    # testmat = [[1,2,3,4],[5,6,7,8]]\n",
    "    # revmat =reverse(testmat) # [[4,3,2,1],[8,7,6,5]]\n",
    "    new=[]\n",
    "    for i in range(len(mat)):\n",
    "        new.append([])\n",
    "        for j in range(len(mat[0])):\n",
    "            new[i].append(mat[i][len(mat[0])-j-1])\n",
    "    return new\n",
    "\n",
    "def transpose(mat):\n",
    "    # transpose\n",
    "    # testmat = [[1,2,3,4],[5,6,7,8]]\n",
    "    # [[1 5]\n",
    "    # [2 6]\n",
    "    # [3 7]\n",
    "    # [4 8]]  \n",
    "    return np.transpose(mat)\n",
    "\n",
    "def cover_up(mat):\n",
    "    # retval\n",
    "    # new: new matrix which has all 0 in each row shifted to left\n",
    "    # done: true if new matrix different from mat\n",
    "    \n",
    "    new = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "    done = False\n",
    "    for i in range(len(mat)):\n",
    "        count = 0\n",
    "        for j in range(len(mat[i])):\n",
    "            if mat[i][j]!=0:\n",
    "                new[i][count] = mat[i][j]\n",
    "                if j!=count:\n",
    "                    done=True\n",
    "                count+=1\n",
    "    return (new,done)\n",
    "\n",
    "def merge(mat):\n",
    "    done=False\n",
    "    score = 0\n",
    "    for i in range(4):\n",
    "        for j in range(3):\n",
    "            if mat[i][j]==mat[i][j+1] and mat[i][j]!=0:\n",
    "                mat[i][j]*=2\n",
    "                score += mat[i][j]   \n",
    "                mat[i][j+1]=0\n",
    "                done=True\n",
    "    return (mat,done,score)\n",
    "\n",
    "#up move\n",
    "def up(game):\n",
    "        game = transpose(game)\n",
    "        game,done = cover_up(game)\n",
    "        temp = merge(game)\n",
    "        game = temp[0]\n",
    "        done = done or temp[1]\n",
    "        game = cover_up(game)[0]\n",
    "        game = transpose(game)\n",
    "        return (game,done,temp[2])\n",
    "\n",
    "#down move\n",
    "def down(game):\n",
    "        game=reverse(transpose(game))\n",
    "        game,done=cover_up(game)\n",
    "        temp=merge(game)\n",
    "        game=temp[0]\n",
    "        done=done or temp[1]\n",
    "        game=cover_up(game)[0]\n",
    "        game=transpose(reverse(game))\n",
    "        return (game,done,temp[2])\n",
    "\n",
    "#left move\n",
    "def left(game):\n",
    "        game,done=cover_up(game)\n",
    "        temp=merge(game)\n",
    "        game=temp[0]\n",
    "        done=done or temp[1]\n",
    "        game=cover_up(game)[0]\n",
    "        return (game,done,temp[2])\n",
    "\n",
    "#right move\n",
    "def right(game):\n",
    "        game=reverse(game)\n",
    "        game,done=cover_up(game)\n",
    "        temp=merge(game)\n",
    "        game=temp[0]\n",
    "        done=done or temp[1]\n",
    "        game=cover_up(game)[0]\n",
    "        game=reverse(game)\n",
    "        return (game,done,temp[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = {0:up,1:left,2:right,3:down}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Functions\n",
    "* Find Empty Cell Function (Used in Reward)\n",
    "* Convert Input Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the input game matrix into corresponding power of 2 matrix.\n",
    "def change_values(X):\n",
    "    power_mat = np.zeros(shape=(1,4,4,16),dtype=np.float32)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if(X[i][j]==0):\n",
    "                power_mat[0][i][j][0] = 1.0\n",
    "            else:\n",
    "                power = int(math.log(X[i][j],2))\n",
    "                power_mat[0][i][j][power] = 1.0\n",
    "    return power_mat        \n",
    "\n",
    "#find the number of empty cells in the game matrix.\n",
    "def findemptyCell(mat):\n",
    "    count = 0\n",
    "    for i in range(len(mat)):\n",
    "        for j in range(len(mat)):\n",
    "            if(mat[i][j]==0):\n",
    "                count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "start_learning_rate = 0.0005\n",
    "\n",
    "#gamma for Q-learning\n",
    "gamma = 0.9\n",
    "\n",
    "#epsilon greedy approach\n",
    "epsilon = 0.9\n",
    "\n",
    "#to store states and lables of the game for training\n",
    "#states of the game\n",
    "replay_memory = list()\n",
    "\n",
    "#labels of the states\n",
    "replay_labels = list()\n",
    "\n",
    "#capacity of memory\n",
    "mem_capacity = 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture\n",
    "\n",
    "![](https://github.com/navjindervirdee/2048-deep-reinforcement-learning/blob/master/Architecture/Architecture.JPG?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first convolution layer depth\n",
    "depth1 = 256\n",
    "\n",
    "#second convolution layer depth\n",
    "depth2 = 128\n",
    "\n",
    "#batch size for batch gradient descent\n",
    "batch_size = 512\n",
    "\n",
    "#input units\n",
    "input_units = 16\n",
    "\n",
    "#fully connected layer neurons\n",
    "hidden_units = 256\n",
    "\n",
    "#output neurons = number of moves\n",
    "output_units = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make the Tensorflow Graph\n",
    "* Loss = mean ( square( Q(st,at) - (r + gamma x max(Q(st+1,a))) ) )\n",
    "* Activation = RELU\n",
    "* Optimizer = RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-4068b7d23c35>:85: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "tf_batch_dataset = tf.placeholder(tf.float32,shape=(batch_size,4,4,16))\n",
    "tf_batch_labels  = tf.placeholder(tf.float32,shape=(batch_size,output_units))\n",
    "\n",
    "single_dataset   = tf.placeholder(tf.float32,shape=(1,4,4,16))\n",
    "\n",
    "#CONV LAYERS\n",
    "#conv layer1 weights\n",
    "conv1_layer1_weights = tf.Variable(tf.truncated_normal([1,2,input_units,depth1],mean=0,stddev=0.01), name='conv1_layer1_weights')\n",
    "conv2_layer1_weights = tf.Variable(tf.truncated_normal([2,1,input_units,depth1],mean=0,stddev=0.01), name='conv2_layer1_weights')\n",
    "\n",
    "#conv layer2 weights\n",
    "conv1_layer2_weights = tf.Variable(tf.truncated_normal([1,2,depth1,depth2],mean=0,stddev=0.01),name='conv1_layer2_weights')\n",
    "conv2_layer2_weights = tf.Variable(tf.truncated_normal([2,1,depth1,depth2],mean=0,stddev=0.01),name='conv2_layer2_weights')\n",
    "\n",
    "#FUllY CONNECTED LAYERS\n",
    "expand_size = 2*4*depth2*2 + 3*3*depth2*2 + 4*3*depth1*2\n",
    "fc_layer1_weights = tf.Variable(tf.truncated_normal([expand_size,hidden_units],mean=0,stddev=0.01),name='fc_layer1_weights')\n",
    "fc_layer1_biases = tf.Variable(tf.truncated_normal([1,hidden_units],mean=0,stddev=0.01),name='fc_layer1_biases')\n",
    "fc_layer2_weights = tf.Variable(tf.truncated_normal([hidden_units,output_units],mean=0,stddev=0.01),name='fc_layer2_weights')\n",
    "fc_layer2_biases = tf.Variable(tf.truncated_normal([1,output_units],mean=0,stddev=0.01),name='fc_layer2_biases')\n",
    "\n",
    "#model\n",
    "def model(dataset):\n",
    "    #layer1\n",
    "    conv1 = tf.nn.conv2d(dataset,conv1_layer1_weights,[1,1,1,1],padding='VALID') \n",
    "    conv2 = tf.nn.conv2d(dataset,conv2_layer1_weights,[1,1,1,1],padding='VALID') \n",
    "    \n",
    "    #layer1 relu activation\n",
    "    relu1 = tf.nn.relu(conv1)\n",
    "    relu2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    #layer2\n",
    "    conv11 = tf.nn.conv2d(relu1,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "    conv12 = tf.nn.conv2d(relu1,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "\n",
    "    conv21 = tf.nn.conv2d(relu2,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "    conv22 = tf.nn.conv2d(relu2,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "\n",
    "    #layer2 relu activation\n",
    "    relu11 = tf.nn.relu(conv11)\n",
    "    relu12 = tf.nn.relu(conv12)\n",
    "    relu21 = tf.nn.relu(conv21)\n",
    "    relu22 = tf.nn.relu(conv22)\n",
    "    \n",
    "    #get shapes of all activations\n",
    "    shape1 = relu1.get_shape().as_list()\n",
    "    shape2 = relu2.get_shape().as_list()\n",
    "    \n",
    "    shape11 = relu11.get_shape().as_list()\n",
    "    shape12 = relu12.get_shape().as_list()\n",
    "    shape21 = relu21.get_shape().as_list()\n",
    "    shape22 = relu22.get_shape().as_list()\n",
    "\n",
    "    #expansion\n",
    "    hidden1 = tf.reshape(relu1,[shape1[0],shape1[1]*shape1[2]*shape1[3]])\n",
    "    hidden2 = tf.reshape(relu2,[shape2[0],shape2[1]*shape2[2]*shape2[3]])\n",
    "    \n",
    "    hidden11 = tf.reshape(relu11,[shape11[0],shape11[1]*shape11[2]*shape11[3]])\n",
    "    hidden12 = tf.reshape(relu12,[shape12[0],shape12[1]*shape12[2]*shape12[3]])\n",
    "    hidden21 = tf.reshape(relu21,[shape21[0],shape21[1]*shape21[2]*shape21[3]])\n",
    "    hidden22 = tf.reshape(relu22,[shape22[0],shape22[1]*shape22[2]*shape22[3]])\n",
    "\n",
    "    #concatenation\n",
    "    hidden = tf.concat([hidden1,hidden2,hidden11,hidden12,hidden21,hidden22],axis=1)\n",
    "\n",
    "    #full connected layers\n",
    "    hidden = tf.matmul(hidden,fc_layer1_weights) + fc_layer1_biases\n",
    "    hidden = tf.nn.relu(hidden)\n",
    "\n",
    "    #output layer\n",
    "    output = tf.matmul(hidden,fc_layer2_weights) + fc_layer2_biases\n",
    "    \n",
    "    #return output\n",
    "    return output\n",
    "\n",
    "#for single example\n",
    "single_output = model(single_dataset)\n",
    "\n",
    "#for batch data\n",
    "logits = model(tf_batch_dataset)\n",
    "\n",
    "#loss\n",
    "loss = tf.square(tf.subtract(tf_batch_labels,logits))\n",
    "loss = tf.reduce_sum(loss,axis=1,keep_dims=True)\n",
    "loss = tf.reduce_mean(loss)/2.0\n",
    "\n",
    "#optimizer\n",
    "global_step = tf.Variable(0,name='global_step')  # count the number of steps taken.\n",
    "learning_rate = tf.train.exponential_decay(float(start_learning_rate), global_step, 1000, 0.90, staircase=True)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "J = []\n",
    "\n",
    "#scores\n",
    "scores = []\n",
    "\n",
    "#to store final parameters\n",
    "final_parameters = {}\n",
    "doublecheck_parameters = {}\n",
    "#number of episodes\n",
    "M = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training dataset and Train Simultaneously\n",
    "* Current Reward = number of merges + log(new max,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_layer1_weights\n",
      "conv2_layer1_weights\n",
      "conv1_layer2_weights\n",
      "conv2_layer2_weights\n",
      "fc_layer1_weights\n",
      "fc_layer1_biases\n",
      "fc_layer2_weights\n",
      "fc_layer2_biases\n",
      "global_step\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for v in tf.trainable_variables():\n",
    "        print(v.name[:-2])\n",
    "        doublecheck_parameters[v.name[:-2]] = session.run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv1_layer1_weights': array([[[[-0.00289692,  0.01654326,  0.00251404, ..., -0.00812861,\n",
      "          -0.00795096, -0.00164373],\n",
      "         [-0.00865933, -0.01214903,  0.00386813, ..., -0.00108689,\n",
      "           0.0121359 ,  0.00907037],\n",
      "         [ 0.00295152,  0.01079029,  0.0026053 , ..., -0.00235824,\n",
      "          -0.00833142,  0.00331028],\n",
      "         ...,\n",
      "         [-0.01653482,  0.00660299,  0.00609448, ...,  0.00168153,\n",
      "           0.00499624, -0.01569415],\n",
      "         [ 0.00180345, -0.00307881,  0.00305528, ...,  0.0048796 ,\n",
      "           0.00591916,  0.00357972],\n",
      "         [-0.00706649,  0.00063175, -0.00935004, ...,  0.01079379,\n",
      "           0.00380014, -0.00722262]],\n",
      "\n",
      "        [[-0.00355211, -0.00495669, -0.01187043, ..., -0.01436884,\n",
      "          -0.01368016, -0.00439329],\n",
      "         [-0.00394974, -0.01588897, -0.01275807, ..., -0.0025552 ,\n",
      "          -0.00457478,  0.0060049 ],\n",
      "         [ 0.00324683,  0.00397197, -0.00858699, ...,  0.00676855,\n",
      "           0.0010614 ,  0.00306259],\n",
      "         ...,\n",
      "         [-0.0045921 ,  0.01230466,  0.00822618, ...,  0.00992925,\n",
      "           0.00555402,  0.00306001],\n",
      "         [-0.01455138, -0.00767168, -0.00010478, ...,  0.00318964,\n",
      "           0.01725922, -0.00967444],\n",
      "         [-0.00330289,  0.00047286,  0.00923452, ...,  0.00320198,\n",
      "          -0.00887738, -0.00590455]]]], dtype=float32), 'conv2_layer1_weights': array([[[[ 5.95019701e-05,  1.53211169e-02, -4.16281819e-03, ...,\n",
      "           5.85742528e-04, -4.88795992e-03, -9.36826412e-03],\n",
      "         [ 1.15958545e-02,  3.78293288e-03, -3.42424464e-04, ...,\n",
      "          -2.66266498e-03,  3.97929037e-03,  1.96130779e-02],\n",
      "         [-7.70927593e-03,  1.35246115e-02,  8.26255139e-03, ...,\n",
      "          -8.37033708e-03,  4.63010743e-03, -1.06175048e-02],\n",
      "         ...,\n",
      "         [-6.44304371e-03, -1.81183908e-02,  4.23281780e-03, ...,\n",
      "           1.97739545e-02, -7.12834392e-03, -1.45967565e-02],\n",
      "         [-1.15791783e-02,  1.03291776e-02, -4.19257302e-03, ...,\n",
      "           5.36502758e-03, -1.88339949e-02, -3.07480246e-03],\n",
      "         [ 4.58242418e-03, -1.21974135e-02, -4.69736662e-03, ...,\n",
      "           1.31776175e-02,  6.89960644e-03,  2.91857682e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 7.87726697e-03, -1.65874306e-02,  8.53286684e-03, ...,\n",
      "          -8.31014069e-04,  7.03731598e-03,  4.00060415e-03],\n",
      "         [-5.17136464e-03,  1.79522987e-02,  8.78900662e-03, ...,\n",
      "          -1.41521194e-03, -1.90543905e-02, -7.08135171e-03],\n",
      "         [ 1.13307126e-02,  1.72221716e-02,  1.18433852e-02, ...,\n",
      "          -4.53494163e-03, -1.77730003e-03,  4.16218117e-03],\n",
      "         ...,\n",
      "         [ 4.08829097e-03,  4.52626450e-03,  1.10708112e-02, ...,\n",
      "          -5.89627726e-03, -1.49355465e-05, -1.29984291e-02],\n",
      "         [-8.41852860e-04, -1.89075973e-02,  4.53664863e-04, ...,\n",
      "           1.14833303e-02, -1.57901812e-02,  1.95575645e-03],\n",
      "         [ 1.36417733e-03,  4.97360528e-03,  4.71122842e-03, ...,\n",
      "          -1.39261745e-02,  1.43841673e-02,  1.38302203e-02]]]],\n",
      "      dtype=float32), 'conv1_layer2_weights': array([[[[-0.01267583,  0.00530599, -0.00622854, ..., -0.01600995,\n",
      "           0.01695789,  0.00828023],\n",
      "         [-0.01037431,  0.00827987,  0.00597131, ..., -0.00554465,\n",
      "          -0.00668487, -0.0061823 ],\n",
      "         [-0.0031994 , -0.00429112,  0.00437737, ...,  0.00762509,\n",
      "          -0.00417126,  0.00543235],\n",
      "         ...,\n",
      "         [-0.01784417,  0.01334596, -0.00052481, ...,  0.00735914,\n",
      "          -0.00292421,  0.00711052],\n",
      "         [-0.00983831,  0.0043053 ,  0.00628506, ...,  0.0114885 ,\n",
      "           0.00269928,  0.00039647],\n",
      "         [-0.0036357 , -0.01393028, -0.00898055, ...,  0.00689725,\n",
      "           0.01986352,  0.00238419]],\n",
      "\n",
      "        [[-0.00659747, -0.00692534,  0.0039823 , ..., -0.00635135,\n",
      "          -0.00126485, -0.00190803],\n",
      "         [-0.00540627,  0.00784373, -0.00895457, ...,  0.00509929,\n",
      "          -0.00399465, -0.00169534],\n",
      "         [ 0.00727383,  0.00090032, -0.0146465 , ...,  0.0037478 ,\n",
      "          -0.00412873, -0.01058398],\n",
      "         ...,\n",
      "         [-0.0044628 , -0.00151961,  0.01375378, ...,  0.00197667,\n",
      "          -0.0104289 , -0.00125086],\n",
      "         [ 0.0180675 ,  0.00192218, -0.00692527, ..., -0.00616134,\n",
      "          -0.0010578 ,  0.00283678],\n",
      "         [ 0.00801693, -0.01549401, -0.0052441 , ..., -0.00442908,\n",
      "           0.00820521, -0.01175372]]]], dtype=float32), 'conv2_layer2_weights': array([[[[ 1.12614082e-03, -1.65544590e-03, -1.85499375e-03, ...,\n",
      "           4.19502798e-03,  6.22955291e-03,  1.53993582e-02],\n",
      "         [-1.16099864e-02, -6.09016744e-03, -3.22595239e-04, ...,\n",
      "          -7.61134503e-03, -1.17570790e-03, -1.00432085e-02],\n",
      "         [-1.08591076e-02, -1.23009980e-02, -1.91665452e-03, ...,\n",
      "           3.18453368e-03, -8.93722475e-03,  1.73549615e-02],\n",
      "         ...,\n",
      "         [ 5.91526181e-03,  1.96411766e-05,  1.13122882e-02, ...,\n",
      "          -7.57496059e-03,  1.58921571e-03, -8.80068261e-03],\n",
      "         [ 2.53017689e-03,  2.97759520e-03,  1.76367965e-02, ...,\n",
      "           1.81913506e-02,  3.42463236e-03, -8.81274138e-03],\n",
      "         [-2.67512118e-03, -4.16757260e-03,  1.50144318e-04, ...,\n",
      "          -3.28106014e-03, -8.60199984e-03, -6.40212931e-03]]],\n",
      "\n",
      "\n",
      "       [[[-1.77180476e-03, -1.70314815e-02, -1.88056994e-02, ...,\n",
      "           4.83766384e-03, -5.37071889e-03, -8.94094817e-03],\n",
      "         [-1.05488515e-02, -1.86127052e-03, -1.81225827e-03, ...,\n",
      "           1.14720101e-02,  3.36635578e-03,  7.88554782e-04],\n",
      "         [ 1.92083251e-02,  5.00154030e-03,  4.64819092e-03, ...,\n",
      "           1.79305568e-03, -5.61862299e-03,  1.28436796e-02],\n",
      "         ...,\n",
      "         [ 3.08424328e-03,  1.47720035e-02,  9.09055769e-03, ...,\n",
      "          -1.20466221e-02,  1.84619264e-03, -4.42513847e-04],\n",
      "         [-5.12880180e-03,  7.39517855e-03,  9.66796838e-03, ...,\n",
      "          -1.65715497e-02,  1.43004339e-02, -1.44730853e-02],\n",
      "         [-1.18207997e-02, -3.26010864e-03,  3.90264182e-03, ...,\n",
      "           1.21986745e-02,  1.54182790e-02,  6.75695622e-03]]]],\n",
      "      dtype=float32), 'fc_layer1_weights': array([[-0.0177082 , -0.00079762,  0.01717664, ..., -0.00181865,\n",
      "        -0.00851105,  0.00229395],\n",
      "       [-0.00292281, -0.01568202,  0.00829526, ..., -0.01013942,\n",
      "        -0.01152119,  0.00910525],\n",
      "       [-0.01776101,  0.00051232,  0.0016992 , ..., -0.01697094,\n",
      "         0.00244023,  0.00955651],\n",
      "       ...,\n",
      "       [-0.00402502,  0.01554602, -0.00436989, ..., -0.01006161,\n",
      "        -0.00195236, -0.00618705],\n",
      "       [-0.00300275, -0.00147529, -0.0018464 , ...,  0.01294025,\n",
      "         0.01047307,  0.00021455],\n",
      "       [ 0.01309438, -0.01337994,  0.00299083, ..., -0.01376916,\n",
      "         0.00096669, -0.00114405]], dtype=float32), 'fc_layer1_biases': array([[ 0.00768597, -0.00185819, -0.00810522, -0.00256932, -0.00412674,\n",
      "        -0.01184302, -0.00188953,  0.01737101,  0.0033372 , -0.00600389,\n",
      "         0.00799128, -0.00153905,  0.00314125, -0.01014884,  0.00757845,\n",
      "        -0.0172113 ,  0.00267681,  0.00228928, -0.0068764 , -0.00972448,\n",
      "         0.00636921, -0.01092331,  0.00024589,  0.00072819,  0.01590151,\n",
      "         0.0029423 , -0.00439113, -0.01001157,  0.00827863, -0.00635294,\n",
      "         0.0082386 , -0.00079147,  0.00592278, -0.01084895, -0.00992776,\n",
      "        -0.00143941,  0.0006669 , -0.00543393, -0.00101707,  0.00805892,\n",
      "        -0.01169193,  0.01665394, -0.01799301, -0.0146246 ,  0.01253539,\n",
      "        -0.00235367, -0.00405185, -0.0120924 , -0.01431934,  0.01038411,\n",
      "        -0.01179222, -0.00985926, -0.00501542,  0.00605055, -0.00344139,\n",
      "        -0.01040937,  0.00467394, -0.00371417, -0.01747865,  0.01118673,\n",
      "         0.00047325,  0.00637388,  0.01420877,  0.00316221,  0.00792878,\n",
      "        -0.01439227,  0.00621289,  0.01907493,  0.00015286, -0.0103093 ,\n",
      "        -0.01261333, -0.00759031,  0.0052377 , -0.01072335, -0.01325426,\n",
      "         0.01183483, -0.01650338,  0.00026029, -0.00332984, -0.00130678,\n",
      "        -0.00962972, -0.00352669,  0.01493252, -0.00039162,  0.01463247,\n",
      "        -0.01259351, -0.00215184, -0.00423999, -0.00115518,  0.00065917,\n",
      "        -0.00747223,  0.00079827,  0.01169223, -0.00170061,  0.00716085,\n",
      "         0.00734333,  0.00737902,  0.01995034, -0.01062137,  0.00620954,\n",
      "        -0.00364875, -0.0044161 , -0.00133145,  0.00010333, -0.00352992,\n",
      "        -0.01842989, -0.00036081, -0.00036959, -0.00609943,  0.00112242,\n",
      "        -0.00082439, -0.00260514, -0.01344068, -0.00201306,  0.00418269,\n",
      "        -0.00514413,  0.00810189,  0.00325545, -0.01298536, -0.00502789,\n",
      "        -0.00313457, -0.00014419,  0.00925887,  0.01080609,  0.004406  ,\n",
      "        -0.01069051,  0.00582049, -0.01628328,  0.00744799,  0.01170194,\n",
      "        -0.0125553 , -0.00393933,  0.00343678, -0.00618872, -0.00014306,\n",
      "        -0.00259317, -0.01300584, -0.01312615,  0.00449667, -0.00414155,\n",
      "         0.00126658,  0.00036158, -0.00569613,  0.00091692, -0.01611816,\n",
      "        -0.00181457, -0.01573857,  0.00460956,  0.00818043,  0.00258271,\n",
      "         0.01722904, -0.00457439, -0.00566172, -0.00190905, -0.01789534,\n",
      "         0.00640102,  0.00920275, -0.00685598,  0.00885921,  0.00803361,\n",
      "        -0.01715148,  0.00976768, -0.00151172,  0.00324484, -0.00951967,\n",
      "        -0.00226011,  0.00668569, -0.00464713, -0.00663202, -0.00641911,\n",
      "        -0.01621486, -0.00852832,  0.00411864, -0.01194243,  0.01301124,\n",
      "         0.01356943,  0.00540324, -0.00183636, -0.00379661,  0.00926216,\n",
      "        -0.00501317,  0.00116835,  0.01323864, -0.00524143,  0.01695159,\n",
      "         0.00035801,  0.01150079, -0.01177661,  0.00517586,  0.01242271,\n",
      "         0.00686234, -0.00240345, -0.00056807,  0.00333149,  0.00871661,\n",
      "        -0.00140423, -0.00745801, -0.00106438,  0.0016821 ,  0.0005042 ,\n",
      "         0.00019033, -0.00795285,  0.00516282, -0.01172963, -0.00462154,\n",
      "         0.00490406, -0.00657012,  0.0089528 , -0.00294787,  0.00792606,\n",
      "         0.01144955, -0.00080917,  0.01189857, -0.00230775,  0.00043458,\n",
      "        -0.01436397, -0.00571865, -0.01090046,  0.00728944,  0.00896788,\n",
      "        -0.01188168, -0.00487568, -0.00627106,  0.00133109,  0.01120268,\n",
      "        -0.00690078, -0.00361697,  0.00106547, -0.00466325,  0.00987864,\n",
      "         0.00433033,  0.01297884, -0.01179936,  0.00693147,  0.00136801,\n",
      "        -0.0134646 , -0.01275659,  0.00093513,  0.00152504, -0.00696178,\n",
      "         0.00072027, -0.01030334,  0.00427576, -0.0093255 ,  0.0038329 ,\n",
      "         0.00478877,  0.00061766, -0.00273562,  0.00271677,  0.00689353,\n",
      "        -0.01094538, -0.00943434,  0.01099357,  0.00470534,  0.00800283,\n",
      "        -0.00758757]], dtype=float32), 'fc_layer2_weights': array([[-0.00770411, -0.01282284,  0.0165503 , -0.00905485],\n",
      "       [-0.01016485, -0.01688893,  0.00437006,  0.00709957],\n",
      "       [ 0.01128689, -0.00491016,  0.00107599,  0.00140422],\n",
      "       ...,\n",
      "       [ 0.00811626,  0.008566  ,  0.00304342,  0.00275243],\n",
      "       [-0.00781693, -0.00572094, -0.0036134 ,  0.00088674],\n",
      "       [ 0.00549706,  0.01029885, -0.00536793, -0.00249671]],\n",
      "      dtype=float32), 'fc_layer2_biases': array([[-0.01129063, -0.0109398 , -0.01574922,  0.00620407]],\n",
      "      dtype=float32), 'global_step': 0}\n"
     ]
    }
   ],
   "source": [
    "print(doublecheck_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Episode 0 finished with score 1256.0, result : lose board : [[4.0, 2.0, 8.0, 2.0], [16.0, 4.0, 128.0, 4.0], [2.0, 8.0, 32.0, 64.0], [4.0, 2.0, 4.0, 2]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 1 finished with score 412.0, result : lose board : [[ 8.  2.  4. 16.]\n",
      " [ 2. 32. 16.  2.]\n",
      " [ 8. 16.  8.  4.]\n",
      " [ 2.  4. 32.  2.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 2 finished with score 1540.0, result : lose board : [[  4.   8.   2.  16.]\n",
      " [  8. 128.  32.   2.]\n",
      " [  4.  32.  64.   8.]\n",
      " [  2.   8.  32.   2.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 3 finished with score 960.0, result : lose board : [[2, 4.0, 8.0, 2.0], [16.0, 32.0, 64.0, 4.0], [4.0, 64.0, 32.0, 8.0], [2.0, 8.0, 2.0, 4.0]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 4 finished with score 1480.0, result : lose board : [[8.0, 4.0, 32.0, 2.0], [2.0, 16.0, 64.0, 16.0], [8.0, 128.0, 32.0, 4.0], [4, 16.0, 4, 2]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 5 finished with score 1472.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [ 32. 128.  16.  32.]\n",
      " [  4.  16.   4.   8.]\n",
      " [  2.  64.   2.   4.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 6 finished with score 900.0, result : lose board : [[8.0, 4.0, 16.0, 4.0], [4.0, 128.0, 4.0, 8.0], [8.0, 4.0, 16.0, 4.0], [4, 8.0, 4, 2]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 7 finished with score 696.0, result : lose board : [[4, 16.0, 4.0, 2], [8.0, 4.0, 64.0, 4.0], [4.0, 32.0, 2.0, 32.0], [2.0, 4.0, 16.0, 8.0]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 8 finished with score 2452.0, result : lose board : [[  2.   4.  16.   4.]\n",
      " [ 64.  32. 256.   2.]\n",
      " [ 32.   8.  16.   4.]\n",
      " [  8.   2.   8.   2.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 9 finished with score 1164.0, result : lose board : [[4.0, 2.0, 8.0, 4.0], [64.0, 4.0, 128.0, 16.0], [4.0, 8.0, 4.0, 2.0], [2, 4.0, 8.0, 4.0]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 10 finished with score 720.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [4.0, 32.0, 16.0, 8.0], [16.0, 8.0, 64.0, 4.0], [2, 4.0, 32.0, 8.0]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 11 finished with score 480.0, result : lose board : [[16.  2.  8.  4.]\n",
      " [ 8. 16. 32.  2.]\n",
      " [ 4. 32.  8. 16.]\n",
      " [ 2. 16.  4.  8.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 12 finished with score 616.0, result : lose board : [[8.0, 16.0, 8.0, 4.0], [2.0, 8.0, 64.0, 8.0], [4.0, 32.0, 4.0, 2], [2, 8, 16.0, 4]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 13 finished with score 1272.0, result : lose board : [[  4.   2.  32.   4.]\n",
      " [ 16.  64.   4.   2.]\n",
      " [  4. 128.   2.   4.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 14 finished with score 488.0, result : lose board : [[16.0, 32.0, 4.0, 2], [4.0, 2.0, 16.0, 32.0], [2.0, 4.0, 32.0, 8.0], [4.0, 2.0, 4.0, 2.0]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 15 finished with score 740.0, result : lose board : [[ 4.  8. 32.  4.]\n",
      " [ 2. 64.  8.  2.]\n",
      " [ 4.  8. 32.  8.]\n",
      " [ 2. 32.  4.  2.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 16 finished with score 640.0, result : lose board : [[2.0, 8.0, 16.0, 4.0], [8.0, 16.0, 4.0, 8.0], [2.0, 64.0, 32.0, 4.0], [4, 16.0, 8.0, 2]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 17 finished with score 436.0, result : lose board : [[4.0, 16.0, 4.0, 2], [16.0, 32.0, 8.0, 32.0], [2.0, 8.0, 16.0, 4.0], [4.0, 2.0, 4.0, 2.0]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 18 finished with score 1204.0, result : lose board : [[  4.   2.  16.   2.]\n",
      " [ 16.   8. 128.   8.]\n",
      " [  4.  64.   4.   2.]\n",
      " [  2.   8.   2.   4.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 19 finished with score 628.0, result : lose board : [[ 4.  8. 16.  2.]\n",
      " [ 8. 16. 64.  4.]\n",
      " [ 2.  8. 32.  8.]\n",
      " [ 4. 16.  4.  2.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 20 finished with score 808.0, result : lose board : [[8.0, 4.0, 8.0, 2.0], [2.0, 32.0, 2.0, 64.0], [8.0, 64.0, 4.0, 8.0], [2, 4.0, 2.0, 4.0]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 21 finished with score 1000.0, result : lose board : [[  2.   8.  16.   4.]\n",
      " [  8.   4.   2.   8.]\n",
      " [  4. 128.   8.   2.]\n",
      " [  2.   4.  32.   8.]], epsilon  : 0.9, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 22 finished with score 1152.0, result : lose board : [[16.0, 8.0, 4, 2], [8.0, 32.0, 8.0, 32.0], [4.0, 128.0, 16.0, 4.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 23 finished with score 1060.0, result : lose board : [[2.0, 8.0, 32.0, 4.0], [4.0, 16.0, 4.0, 2.0], [8.0, 128.0, 16.0, 8.0], [2, 16.0, 8.0, 2]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 24 finished with score 712.0, result : lose board : [[2.0, 32.0, 4.0, 16.0], [16.0, 64.0, 8.0, 4.0], [4.0, 32.0, 4.0, 2.0], [2, 4.0, 8.0, 4]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 25 finished with score 1076.0, result : lose board : [[ 8.  2.  4. 32.]\n",
      " [ 2.  8. 32.  4.]\n",
      " [ 8. 64. 16. 64.]\n",
      " [ 2. 32.  4.  2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 26 finished with score 1120.0, result : lose board : [[  2. 128.   4.   2.]\n",
      " [ 16.   4.   2.  32.]\n",
      " [  8.  16.   8.   4.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 27 finished with score 1256.0, result : lose board : [[8.0, 16.0, 4.0, 2.0], [16.0, 128.0, 8.0, 4.0], [2.0, 8.0, 64.0, 8.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 28 finished with score 448.0, result : lose board : [[ 2.  8.  2.  4.]\n",
      " [ 8. 16.  4. 64.]\n",
      " [ 2.  8. 16.  8.]\n",
      " [ 4.  2.  4.  2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 29 finished with score 720.0, result : lose board : [[ 2.  4.  2.  4.]\n",
      " [ 4. 64.  4.  8.]\n",
      " [ 8.  4. 16.  4.]\n",
      " [ 4. 64.  4.  2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 30 finished with score 480.0, result : lose board : [[ 2. 16.  8.  2.]\n",
      " [64.  8. 16.  8.]\n",
      " [ 8.  2.  4.  2.]\n",
      " [ 2.  8.  2.  4.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 31 finished with score 1316.0, result : lose board : [[2, 16.0, 8.0, 4], [128.0, 64.0, 2.0, 8.0], [4.0, 8.0, 32.0, 4.0], [2.0, 16.0, 4.0, 2.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 32 finished with score 552.0, result : lose board : [[32.0, 2.0, 4.0, 2.0], [4.0, 16.0, 2.0, 8.0], [8.0, 64.0, 4, 2], [2, 16.0, 2, 4]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 33 finished with score 712.0, result : lose board : [[ 2.  4. 16.  4.]\n",
      " [ 4.  8. 32. 16.]\n",
      " [ 8. 32. 64.  8.]\n",
      " [ 4.  8.  4.  2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 34 finished with score 1336.0, result : lose board : [[  2.   4.  16.   2.]\n",
      " [  8.  64. 128.  32.]\n",
      " [  4.  16.   4.   8.]\n",
      " [  2.   4.  16.   2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 35 finished with score 660.0, result : lose board : [[8, 2.0, 4.0, 2], [32.0, 8.0, 32.0, 8.0], [2.0, 64.0, 2.0, 4.0], [4.0, 16.0, 8.0, 2.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 36 finished with score 1404.0, result : lose board : [[  2.   4.   2. 128.]\n",
      " [ 16.  32.  64.   2.]\n",
      " [  2.  16.   2.   8.]\n",
      " [  4.  32.   4.   2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 37 finished with score 520.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [16.0, 64.0, 2.0, 4.0], [4.0, 32.0, 8.0, 2], [2.0, 8.0, 2.0, 4.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 38 finished with score 2660.0, result : lose board : [[  4.  64.   2.   8.]\n",
      " [ 16. 256.  16.   2.]\n",
      " [  4.  64.   4.  16.]\n",
      " [  2.   8.  32.   2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 39 finished with score 1296.0, result : lose board : [[  2.  64.   8.   4.]\n",
      " [  4.  32. 128.   2.]\n",
      " [  8.   4.   8.   4.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 40 finished with score 956.0, result : lose board : [[2.0, 8.0, 16.0, 4.0], [16.0, 128.0, 8.0, 2], [8.0, 4.0, 16.0, 4.0], [4.0, 8.0, 4.0, 2.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 41 finished with score 588.0, result : lose board : [[2.0, 16.0, 8.0, 2], [16.0, 4.0, 64.0, 8.0], [4.0, 2.0, 16.0, 4.0], [2.0, 4.0, 32.0, 2.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 42 finished with score 820.0, result : lose board : [[4.0, 64.0, 4.0, 2], [8.0, 32.0, 16.0, 4.0], [4.0, 8.0, 4.0, 32.0], [2.0, 16.0, 32.0, 4.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 43 finished with score 1188.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [ 16.  64. 128.   8.]\n",
      " [  2.   4.   8.   4.]\n",
      " [  4.   2.   4.   2.]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 44 finished with score 908.0, result : lose board : [[2, 4.0, 8.0, 4.0], [4.0, 64.0, 4.0, 32.0], [2.0, 32.0, 64.0, 4.0], [4.0, 8.0, 4.0, 2.0]], epsilon  : 0.8955223880597016, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 45 finished with score 1372.0, result : lose board : [[2.0, 4.0, 16.0, 4.0], [16.0, 32.0, 64.0, 8.0], [4.0, 128.0, 8.0, 16.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.8910670527957231, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 46 finished with score 560.0, result : lose board : [[2.0, 32.0, 2.0, 8.0], [8.0, 4.0, 8.0, 4.0], [4.0, 64.0, 2.0, 16.0], [2, 4.0, 8.0, 2.0]], epsilon  : 0.8910670527957231, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 47 finished with score 1384.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 16. 128.  32.  16.]\n",
      " [  4.  64.   8.   4.]\n",
      " [  8.   2.  16.   2.]], epsilon  : 0.8910670527957231, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 48 finished with score 648.0, result : lose board : [[4.0, 2.0, 16.0, 2.0], [2.0, 8.0, 32.0, 8.0], [8.0, 16.0, 64.0, 16.0], [2, 4.0, 16.0, 2.0]], epsilon  : 0.8910670527957231, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 49 finished with score 628.0, result : lose board : [[ 2.  4.  2. 16.]\n",
      " [ 4.  8. 32.  4.]\n",
      " [ 8. 64.  8. 16.]\n",
      " [ 2. 16.  2.  4.]], epsilon  : 0.8910670527957231, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 50 finished with score 1136.0, result : lose board : [[2.0, 4.0, 16.0, 2.0], [32.0, 8.0, 2.0, 4.0], [16.0, 32.0, 8.0, 128.0], [2, 8.0, 2, 4]], epsilon  : 0.8910670527957231, learning rate : 0.0005000000237487257 \n",
      "\n",
      "Episode 51 finished with score 1996.0, result : lose board : [[2, 16.0, 4.0, 2], [8.0, 4.0, 8.0, 16.0], [4.0, 256.0, 32.0, 4.0], [2.0, 4.0, 8.0, 2.0]], epsilon  : 0.8910670527957231, learning rate : 0.0005000000237487257 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c0cc5167a2f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[0mtemp_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msingle_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtemp_state\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0mtemp_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[0mmax_qvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1359\u001b[0m                            run_metadata)\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\avu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1439\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1440\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1441\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    global epsilon\n",
    "    global replay_labels\n",
    "    global replay_memory\n",
    "\n",
    "    #for episode with max score\n",
    "    maximum = -1\n",
    "    episode = -1\n",
    "    \n",
    "    #total_iters \n",
    "    total_iters = 1\n",
    "    \n",
    "    #number of back props\n",
    "    back=0\n",
    "    \n",
    "    for ep in range(M):\n",
    "        global board\n",
    "        board = new_game(4)\n",
    "        add_two(board)\n",
    "        add_two(board)\n",
    "        \n",
    "        #whether episode finished or not\n",
    "        finish = 'not over'\n",
    "        \n",
    "        #total_score of this episode\n",
    "        total_score = 0\n",
    "        \n",
    "        #iters per episode\n",
    "        local_iters = 1\n",
    "        \n",
    "        while(finish=='not over'):\n",
    "            prev_board = deepcopy(board)\n",
    "            \n",
    "            #get the required move for this state\n",
    "            state = deepcopy(board)\n",
    "            state = change_values(state)\n",
    "            state = np.array(state,dtype = np.float32).reshape(1,4,4,16)\n",
    "            feed_dict = {single_dataset:state}\n",
    "            control_scores = session.run(single_output,feed_dict=feed_dict)\n",
    "            \n",
    "            #find the move with max Q value\n",
    "            control_buttons = np.flip(np.argsort(control_scores),axis=1)\n",
    "            \n",
    "            #copy the Q-values as labels\n",
    "            labels = deepcopy(control_scores[0]) #somehow control_scores has the shape of [[a,b,c,d]]\n",
    "            \n",
    "            #generate random number for epsilon greedy approach\n",
    "            num = random.uniform(0,1)\n",
    "            \n",
    "            #store prev max\n",
    "            prev_max = np.max(prev_board)\n",
    "            \n",
    "            #num is less epsilon generate random move\n",
    "            if(num<epsilon):\n",
    "                #find legal moves\n",
    "                legal_moves = list()\n",
    "                for i in range(4):\n",
    "                    temp_board = deepcopy(prev_board)\n",
    "                    temp_board,_,_ = controls[i](temp_board)\n",
    "                    if(np.array_equal(temp_board,prev_board)):\n",
    "                        continue\n",
    "                    else:\n",
    "                        legal_moves.append(i)\n",
    "                if(len(legal_moves)==0):\n",
    "                    finish = 'lose'\n",
    "                    continue\n",
    "                \n",
    "                #generate random move.\n",
    "                random_move = random.sample(legal_moves,1)[0]\n",
    "                \n",
    "                #apply the move\n",
    "                temp_state = deepcopy(prev_board)\n",
    "                temp_state,_,score = controls[random_move](temp_state)\n",
    "                total_score += score\n",
    "                finish = game_state(temp_state)\n",
    "                \n",
    "                #get number of merges\n",
    "                empty1 = findemptyCell(prev_board)\n",
    "                empty2 = findemptyCell(temp_state)\n",
    "                \n",
    "                if(finish=='not over'):\n",
    "                    temp_state = add_two(temp_state)\n",
    "\n",
    "                board = deepcopy(temp_state)\n",
    "\n",
    "                #get next max after applying the move\n",
    "                next_max = np.max(temp_state)\n",
    "                \n",
    "                #reward math.log(next_max,2)*0.1 if next_max is higher than prev max\n",
    "                labels[random_move] = (math.log(next_max,2))*0.1\n",
    "                \n",
    "                if(next_max==prev_max):\n",
    "                    labels[random_move] = 0\n",
    "                \n",
    "                #reward is also the number of merges\n",
    "                labels[random_move] += (empty2-empty1)\n",
    "                \n",
    "                #get the next state max Q-value\n",
    "                temp_state = change_values(temp_state)\n",
    "                temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
    "                feed_dict = {single_dataset:temp_state}\n",
    "                temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
    "                    \n",
    "                max_qvalue = np.max(temp_scores)\n",
    "                \n",
    "                #final labels add gamma*max_qvalue\n",
    "                labels[random_move] = (labels[random_move] + gamma*max_qvalue)\n",
    "            \n",
    "            #generate the the max predicted move\n",
    "            else:\n",
    "                for con in control_buttons[0]:\n",
    "                    prev_state = deepcopy(prev_board)\n",
    "                    \n",
    "                    #apply the LEGAl Move with max q_value\n",
    "                    temp_state,_,score = controls[con](prev_state)\n",
    "                    \n",
    "                    #if illegal move label = 0\n",
    "                    if(np.array_equal(prev_board,temp_state)):\n",
    "                        labels[con] = 0\n",
    "                        continue\n",
    "                        \n",
    "                    #get number of merges\n",
    "                    empty1 = findemptyCell(prev_board)\n",
    "                    empty2 = findemptyCell(temp_state)\n",
    "\n",
    "                    \n",
    "                    temp_state = add_two(temp_state)\n",
    "                    board = deepcopy(temp_state)\n",
    "                    total_score += score\n",
    "\n",
    "                    next_max = np.max(temp_state)\n",
    "                    \n",
    "                    #reward\n",
    "                    labels[con] = (math.log(next_max,2))*0.1\n",
    "                    if(next_max==prev_max):\n",
    "                        labels[con] = 0\n",
    "                    \n",
    "                    labels[con] += (empty2-empty1)\n",
    "\n",
    "                    #get next max qvalue\n",
    "                    temp_state = change_values(temp_state)\n",
    "                    temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
    "                    feed_dict = {single_dataset:temp_state}\n",
    "                    temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
    "\n",
    "                    max_qvalue = np.max(temp_scores)\n",
    "\n",
    "                    #final labels\n",
    "                    labels[con] = (labels[con] + gamma*max_qvalue)\n",
    "                    break\n",
    "                    \n",
    "                if(np.array_equal(prev_board,board)):\n",
    "                    finish = 'lose'\n",
    "            \n",
    "            #decrease the epsilon value\n",
    "            if((ep>10000) or (epsilon>0.1 and total_iters%2500==0)):\n",
    "                epsilon = epsilon/1.005\n",
    "                \n",
    "           \n",
    "            #change the matrix values and store them in memory\n",
    "            prev_state = deepcopy(prev_board)\n",
    "            prev_state = change_values(prev_state)\n",
    "            prev_state = np.array(prev_state,dtype=np.float32).reshape(1,4,4,16)\n",
    "            replay_labels.append(labels)\n",
    "            replay_memory.append(prev_state)\n",
    "            \n",
    "            \n",
    "            #back-propagation\n",
    "            if(len(replay_memory)>=mem_capacity):\n",
    "                back_loss = 0\n",
    "                batch_num = 0\n",
    "                z = list(zip(replay_memory,replay_labels))\n",
    "                np.random.shuffle(z)\n",
    "                np.random.shuffle(z)\n",
    "                replay_memory,replay_labels = zip(*z)\n",
    "                \n",
    "                for i in range(0,len(replay_memory),batch_size):\n",
    "                    if(i + batch_size>len(replay_memory)):\n",
    "                        break\n",
    "                        \n",
    "                    batch_data = deepcopy(replay_memory[i:i+batch_size])\n",
    "                    batch_labels = deepcopy(replay_labels[i:i+batch_size])\n",
    "                    \n",
    "                    batch_data = np.array(batch_data,dtype=np.float32).reshape(batch_size,4,4,16)\n",
    "                    batch_labels = np.array(batch_labels,dtype=np.float32).reshape(batch_size,output_units)\n",
    "                \n",
    "                    feed_dict = {tf_batch_dataset: batch_data, tf_batch_labels: batch_labels}\n",
    "                    _,l = session.run([optimizer,loss],feed_dict=feed_dict)\n",
    "                    back_loss += l \n",
    "                    \n",
    "                    print(\"Mini-Batch - {} Back-Prop : {}, Loss : {}\".format(batch_num,back,l))\n",
    "                    batch_num +=1\n",
    "                back_loss /= batch_num\n",
    "                J.append(back_loss)\n",
    "                \n",
    "                #store the parameters in a dictionary\n",
    "                final_parameters['conv1_layer1_weights'] = session.run(conv1_layer1_weights)\n",
    "                final_parameters['conv2_layer1_weights'] = session.run(conv2_layer1_weights)\n",
    "                final_parameters['fc_layer1_weights'] = session.run(fc_layer1_weights)\n",
    "                final_parameters['fc_layer1_biases'] = session.run(fc_layer1_biases)\n",
    "                \n",
    "                for v in tf.trainable_variables():\n",
    "                    doublecheck_parameters[v.name[:-2]] = session.run(v)\n",
    "                    \n",
    "                #number of back-props\n",
    "                back+=1\n",
    "                \n",
    "                #make new memory \n",
    "                replay_memory = list()\n",
    "                replay_labels = list()\n",
    "                \n",
    "            \n",
    "            if(local_iters%400==0):\n",
    "                print(\"Episode : {}, Score : {}, Iters : {}, Finish : {}\".format(ep,total_score,local_iters,finish))\n",
    "            \n",
    "            local_iters += 1\n",
    "            total_iters += 1\n",
    "            \n",
    "        scores.append(total_score)\n",
    "        print(\"Episode {} finished with score {}, result : {} board : {}, epsilon  : {}, learning rate : {} \".format(ep,total_score,finish,board,epsilon,session.run(learning_rate)))\n",
    "        print()\n",
    "        \n",
    "        if((ep+1)%1000==0):\n",
    "            print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))    \n",
    "            print(\"Loss : {}\".format(J[len(J)-1]))\n",
    "            print()\n",
    "            \n",
    "        if(maximum<total_score):\n",
    "            maximum = total_score\n",
    "            episode = ep\n",
    "    print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Trained Weights in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "THIS_FOLDER = os.path.abspath('')\n",
    "PARENT_FOLDER = os.path.dirname(THIS_FOLDER)\n",
    "WEIGHT_FOLDER = os.path.join(PARENT_FOLDER, 'ver2_result')\n",
    "\n",
    "def SaveWeights():\n",
    "    for name,weights in doublecheck_parameters.items():\n",
    "        flatten = weights.reshape(-1,1)\n",
    "        filename = name + '.csv'\n",
    "        file = open(os.path.join(WEIGHT_FOLDER, filename), 'w')\n",
    "        file.write('Sno,Weight\\n')\n",
    "        for i in range(flatten.shape[0]):\n",
    "            file.write(str(i) +',' +str(flatten[i][0])+'\\n')\n",
    "        file.close()\n",
    "        print(filename + \" written!\")\n",
    "        \n",
    "    \n",
    "        \n",
    "SaveWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(WEIGHT_FOLDER,'scores'), scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(WEIGHT_FOLDER,'J'), J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(scores_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
